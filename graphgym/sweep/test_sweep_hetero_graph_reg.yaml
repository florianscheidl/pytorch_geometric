program: graphgym/liwich_main.py
command:
  - ${interpreter}
  - ${program}
  - "--cfg"
  - "graphgym/configs/hetero_AULT_graph_regr.yaml"
  - "--repeat"
  - "1"
  - ${args_no_hyphens}
method: grid
parameters:

  # General
  seed:
    values: [0]

  # dataset -> in the config file
  dataset.name:
    value: TU_QM9
  dataset.task:
    value: graph
  dataset.task_type:
    values: regression
  dataset.pre_transform:
    value: lift_and_wire # 'lift_and_wire'

  # training
  train.batch_size:
    value: 32
  optim.max_epoch:
    value: 1 # default: 200
  train.eval_period:
    value: 10

  # NN parameters
  gnn.act:
    value: relu
  gnn.batchnorm:
    value: True

  # GNN Specific params
  gnn.dim_inner:
    value: 8 # give as list of length # total layers - 1 or dict {pre_inner: [], mp_inner: [], post_inner: []}
  gnn.layers_pre_mp:
    value: 1
  gnn.layers_mp:
    value: 1 # hyperparameter search
  gnn.layers_post_mp:
    value: 1 # hyperparameter search
  gnn.stage_type:
    value: skipconcat
  model.graph_pooling:
    value: add

  # Model-specific GNN params:
  gnn.graph_type:
    value: hetero

  ## lifting:
  lift.data_model:
    value: cell_complex
  lift.method:
    values: [ clique, rings ]
  lift.max_clique_dim:
    value: 3
  lift.max_simple_cycle_length:
    value: 3
  lift.max_induced_cycle_length:
    value: 5
  lift.init_edges:
    value: True
  lift.init_rings:
    value: True
  lift.init_method:
    value: sum

  ## choosing heterogeneous GRL architecture
  gnn.layer_type:
    value: 'heteroconv' # hanconv, hgtconv # requires graph_type == hetero
  # add more arguments in case of using heteroconv

  # Regularization
  gnn.dropout:
    value: "0.0" # Hyperparameter search

  # Optimizer
  optim.base_lr:
    value: 0.001
  optim.scheduler:
    value: 'step'
  optim.steps:
    value: [30,60,90]
  optim.lr_decay:
    value: 0.5
  optim.patience:
    value: 10
  optim.lr_scheduler_min_lr:
    value: 1e-5
